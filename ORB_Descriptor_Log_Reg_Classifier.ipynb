{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql import Row, SparkSession \n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "# for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\"\n",
    "meta_data = spark.read.format('csv').options(header='true', inferschema='true').load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------+------------+----------------------+----------------------+\n",
      "|_c0| X_ray_image_name| Label|Dataset_type|Label_2_Virus_category|Label_1_Virus_category|\n",
      "+---+-----------------+------+------------+----------------------+----------------------+\n",
      "|  0|IM-0128-0001.jpeg|Normal|       TRAIN|                  null|                  null|\n",
      "|  1|IM-0127-0001.jpeg|Normal|       TRAIN|                  null|                  null|\n",
      "|  2|IM-0125-0001.jpeg|Normal|       TRAIN|                  null|                  null|\n",
      "|  3|IM-0122-0001.jpeg|Normal|       TRAIN|                  null|                  null|\n",
      "|  4|IM-0119-0001.jpeg|Normal|       TRAIN|                  null|                  null|\n",
      "+---+-----------------+------+------------+----------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_with_labels = meta_data.withColumn(\n",
    "    'new_label',\n",
    "    F.when((F.col(\"Label\")  ==\"Normal\"), 0).otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  5910\n",
      "Train samples:  5286\n",
      "Test samples:  624\n"
     ]
    }
   ],
   "source": [
    "number_of_samples = meta_data_with_labels.count()\n",
    "train_set = meta_data_with_labels.where(meta_data.Dataset_type == \"TRAIN\")\n",
    "test_set = meta_data_with_labels.where(meta_data.Dataset_type == \"TEST\")\n",
    "num_train = train_set.count()\n",
    "num_test = test_set.count()\n",
    "\n",
    "print(f\"Number of samples: \",number_of_samples )\n",
    "print(f\"Train samples: \", num_train)\n",
    "print(f\"Test samples: \",num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.getcwd() +'/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/'\n",
    "@udf(returnType=StringType())\n",
    "def get_absolute_path(img_file):\n",
    "    abs_path = train_path+str(img_file)\n",
    "    return abs_path\n",
    "train = train_set.withColumn(\"image_path\", get_absolute_path(col(\"X_ray_image_name\")))\n",
    "\n",
    "test_path = os.getcwd() +'/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test/'\n",
    "@udf(returnType=StringType())\n",
    "def get_test_absolute_path(img_file):\n",
    "    abs_path = test_path+str(img_file)\n",
    "    return abs_path\n",
    "test = test_set.withColumn(\"image_path\", get_test_absolute_path(col(\"X_ray_image_name\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5286\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "# TODO Only selecting the 3 colums,we need. Can change later on\n",
    "select_train = train.select(\"image_path\", \"new_label\")\n",
    "select_test = test.select(\"image_path\", \"new_label\")\n",
    "# select_train.show(4)\n",
    "# select_test.show(4)\n",
    "print(select_train.count())\n",
    "print(select_test.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Images to Orb Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|          image_path|new_label|         descriptors|\n",
      "+--------------------+---------+--------------------+\n",
      "|/Users/mma525/Doc...|        0|[73, 50, 24, 32, ...|\n",
      "|/Users/mma525/Doc...|        0|[179, 225, 108, 6...|\n",
      "|/Users/mma525/Doc...|        0|[252, 23, 246, 95...|\n",
      "|/Users/mma525/Doc...|        0|[197, 237, 172, 1...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "+--------------------+---------+--------------------+\n",
      "|          image_path|new_label|         descriptors|\n",
      "+--------------------+---------+--------------------+\n",
      "|/Users/mma525/Doc...|        0|[165, 248, 133, 8...|\n",
      "|/Users/mma525/Doc...|        0|[140, 159, 122, 2...|\n",
      "|/Users/mma525/Doc...|        0|[2, 174, 170, 185...|\n",
      "|/Users/mma525/Doc...|        0|[188, 255, 94, 78...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "5286\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "udf_image = udf(lambda img: get_desc(img), ArrayType(FloatType()))\n",
    "\n",
    "def fetch_descriptor(img):\n",
    "    \n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.resize(image, (700, 700))\n",
    "    orb_cv = cv2.ORB_create(nfeatures=50)\n",
    "    keypts_for_orb, descriptor = orb_cv.detectAndCompute(image, None)\n",
    "    \n",
    "\n",
    "    if descriptor is None:\n",
    "        descriptor = []\n",
    "    else:\n",
    "        descriptor = descriptor.flatten().tolist()\n",
    "    return descriptor\n",
    "\n",
    "udf_image = udf(fetch_descriptor, ArrayType(IntegerType()))\n",
    "\n",
    "# TODO need to do for test data as well\n",
    "# change afterwards\n",
    "train_descriptor = select_train.withColumn(\"descriptors\", udf_image(\"image_path\"))\n",
    "train_descriptor = train_descriptor.filter(train_descriptor.descriptors. isNotNull())\n",
    "\n",
    "\n",
    "test_descriptor = select_test.withColumn(\"descriptors\", udf_image(\"image_path\"))\n",
    "test_descriptor = test_descriptor.filter(test_descriptor.descriptors. isNotNull())\n",
    "\n",
    "\n",
    "\n",
    "train_descriptor.show(4)\n",
    "test_descriptor.show(4)\n",
    "print(train_descriptor.count())\n",
    "print(test_descriptor.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples:  3769\n",
      "Total test examples:  465\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "train_filtered = train_descriptor.filter(size('descriptors')==1600)\n",
    "test_filtered = test_descriptor.filter(size('descriptors')==1600)\n",
    "\n",
    "\n",
    "print(\"Total train examples: \",train_filtered.count())\n",
    "print(\"Total test examples: \",test_filtered.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train examples:  3769\n",
      "Total test examples:  465\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "train_with_vec = train_filtered.withColumn(\"vec_descriptors\", list_to_vector_udf(\"descriptors\"))\n",
    "test_with_vec = test_filtered.withColumn(\"vec_descriptors\", list_to_vector_udf(\"descriptors\"))\n",
    "\n",
    "print(\"Total train examples: \",train_with_vec.count())\n",
    "print(\"Total test examples: \",test_with_vec.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training into 90/10 into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|          image_path|new_label|         descriptors|     vec_descriptors|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|/Users/mma525/Doc...|        1|[65, 249, 57, 34,...|[65.0,249.0,57.0,...|\n",
      "|/Users/mma525/Doc...|        1|[77, 108, 175, 95...|[77.0,108.0,175.0...|\n",
      "|/Users/mma525/Doc...|        1|[124, 78, 132, 19...|[124.0,78.0,132.0...|\n",
      "|/Users/mma525/Doc...|        1|[161, 4, 79, 85, ...|[161.0,4.0,79.0,8...|\n",
      "|/Users/mma525/Doc...|        1|[213, 76, 159, 22...|[213.0,76.0,159.0...|\n",
      "|/Users/mma525/Doc...|        1|[35, 172, 97, 13,...|[35.0,172.0,97.0,...|\n",
      "|/Users/mma525/Doc...|        1|[195, 222, 238, 3...|[195.0,222.0,238....|\n",
      "|/Users/mma525/Doc...|        1|[191, 59, 107, 64...|[191.0,59.0,107.0...|\n",
      "|/Users/mma525/Doc...|        1|[124, 20, 243, 76...|[124.0,20.0,243.0...|\n",
      "|/Users/mma525/Doc...|        1|[224, 161, 185, 1...|[224.0,161.0,185....|\n",
      "|/Users/mma525/Doc...|        1|[217, 48, 151, 18...|[217.0,48.0,151.0...|\n",
      "|/Users/mma525/Doc...|        1|[7, 54, 225, 145,...|[7.0,54.0,225.0,1...|\n",
      "|/Users/mma525/Doc...|        1|[82, 184, 181, 88...|[82.0,184.0,181.0...|\n",
      "|/Users/mma525/Doc...|        1|[252, 224, 145, 2...|[252.0,224.0,145....|\n",
      "|/Users/mma525/Doc...|        1|[4, 138, 142, 63,...|[4.0,138.0,142.0,...|\n",
      "|/Users/mma525/Doc...|        1|[80, 34, 86, 45, ...|[80.0,34.0,86.0,4...|\n",
      "|/Users/mma525/Doc...|        1|[17, 0, 84, 21, 1...|[17.0,0.0,84.0,21...|\n",
      "|/Users/mma525/Doc...|        1|[235, 157, 253, 2...|[235.0,157.0,253....|\n",
      "|/Users/mma525/Doc...|        1|[26, 207, 98, 156...|[26.0,207.0,98.0,...|\n",
      "|/Users/mma525/Doc...|        1|[191, 31, 127, 94...|[191.0,31.0,127.0...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|          image_path|new_label|         descriptors|     vec_descriptors|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|/Users/mma525/Doc...|        1|[47, 191, 226, 20...|[47.0,191.0,226.0...|\n",
      "|/Users/mma525/Doc...|        1|[33, 38, 85, 69, ...|[33.0,38.0,85.0,6...|\n",
      "|/Users/mma525/Doc...|        0|[120, 119, 41, 16...|[120.0,119.0,41.0...|\n",
      "|/Users/mma525/Doc...|        0|[242, 30, 126, 93...|[242.0,30.0,126.0...|\n",
      "|/Users/mma525/Doc...|        0|[24, 136, 142, 18...|[24.0,136.0,142.0...|\n",
      "|/Users/mma525/Doc...|        0|[52, 205, 87, 254...|[52.0,205.0,87.0,...|\n",
      "|/Users/mma525/Doc...|        0|[5, 103, 96, 5, 1...|[5.0,103.0,96.0,5...|\n",
      "|/Users/mma525/Doc...|        0|[242, 30, 126, 92...|[242.0,30.0,126.0...|\n",
      "|/Users/mma525/Doc...|        0|[236, 164, 156, 1...|[236.0,164.0,156....|\n",
      "|/Users/mma525/Doc...|        0|[242, 87, 125, 76...|[242.0,87.0,125.0...|\n",
      "|/Users/mma525/Doc...|        0|[177, 184, 190, 9...|[177.0,184.0,190....|\n",
      "|/Users/mma525/Doc...|        0|[117, 10, 138, 44...|[117.0,10.0,138.0...|\n",
      "|/Users/mma525/Doc...|        0|[141, 245, 25, 75...|[141.0,245.0,25.0...|\n",
      "|/Users/mma525/Doc...|        0|[209, 220, 28, 62...|[209.0,220.0,28.0...|\n",
      "|/Users/mma525/Doc...|        0|[204, 174, 213, 2...|[204.0,174.0,213....|\n",
      "|/Users/mma525/Doc...|        0|[118, 14, 201, 10...|[118.0,14.0,201.0...|\n",
      "|/Users/mma525/Doc...|        0|[57, 89, 31, 12, ...|[57.0,89.0,31.0,1...|\n",
      "|/Users/mma525/Doc...|        0|[113, 233, 24, 17...|[113.0,233.0,24.0...|\n",
      "|/Users/mma525/Doc...|        0|[234, 190, 8, 185...|[234.0,190.0,8.0,...|\n",
      "|/Users/mma525/Doc...|        0|[136, 74, 26, 255...|[136.0,74.0,26.0,...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total train split:  3399\n",
      "Total validation split:  370\n"
     ]
    }
   ],
   "source": [
    "train, val = train_with_vec.randomSplit([0.9, 0.1])\n",
    "train.show()\n",
    "val.show()\n",
    "print(\"Total train split: \",train.count())\n",
    "print(\"Total validation split: \",val.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model and train on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic_regression = LogisticRegression(featuresCol = 'vec_descriptors', labelCol = 'new_label', maxIter=100)\n",
    "logistic_regression_model = logistic_regression.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        1|[0.13442505324830...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[1.92258211262361...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[9.82620723655403...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[3.55770393553846...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train = logistic_regression_model.transform(train)\n",
    "predictions_train.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Area Under ROC:  0.9999924207973321\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Train Area Under ROC: ', evaluator.evaluate(predictions_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.999117387466902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Train Accuracy: ', evaluator.evaluate(predictions_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        1|[4.78632757097569...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[1.57464035524034...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[0.96248971097563...|       0.0|\n",
      "|/Users/mma525/Doc...|        0|[3.80229589954006...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_val = logistic_regression_model.transform(val)\n",
    "predictions_val.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Area Under ROC:  0.7197338830584702\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Val Area Under ROC: ', evaluator.evaluate(predictions_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.6513513513513514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Val Accuracy: ', evaluator.evaluate(predictions_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        0|[3.78053985190336...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[3.21354721515507...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[0.99999999999451...|       0.0|\n",
      "|/Users/mma525/Doc...|        0|[5.11732252417787...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = test_with_vec\n",
    "predictions_test = logistic_regression_model.transform(test)\n",
    "predictions_test.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.6741709230883115\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Test Area Under ROC: ', evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6387096774193548\n"
     ]
    }
   ],
   "source": [
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Test Accuracy: ', evaluator.evaluate(predictions_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
