{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql import Row, SparkSession \n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "# for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\"\n",
    "meta_data = spark.read.format('csv').options(header='true', inferschema='true').load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_with_labels = meta_data.withColumn(\n",
    "    'new_label',\n",
    "    F.when((F.col(\"Label\")  ==\"Normal\"), 0).otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = meta_data_with_labels.count()\n",
    "train_set = meta_data_with_labels.where(meta_data.Dataset_type == \"TRAIN\")\n",
    "test_set = meta_data_with_labels.where(meta_data.Dataset_type == \"TEST\")\n",
    "# num_train = train_set.count()\n",
    "# num_test = test_set.count()\n",
    "\n",
    "# print(f\"Number of samples: \",number_of_samples )\n",
    "# print(f\"Train samples: \", num_train)\n",
    "# print(f\"Test samples: \",num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.getcwd() +'/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/'\n",
    "@udf(returnType=StringType())\n",
    "def get_absolute_path(img_file):\n",
    "    abs_path = train_path+str(img_file)\n",
    "    return abs_path\n",
    "train = train_set.withColumn(\"image_path\", get_absolute_path(col(\"X_ray_image_name\")))\n",
    "\n",
    "test_path = os.getcwd() +'/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test/'\n",
    "@udf(returnType=StringType())\n",
    "def get_test_absolute_path(img_file):\n",
    "    abs_path = test_path+str(img_file)\n",
    "    return abs_path\n",
    "test = test_set.withColumn(\"image_path\", get_test_absolute_path(col(\"X_ray_image_name\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_train = train.select(\"image_path\", \"new_label\")\n",
    "select_test = test.select(\"image_path\", \"new_label\")\n",
    "# select_train.show(4)\n",
    "# select_test.show(4)\n",
    "#print(select_train.count())\n",
    "#print(select_test.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to Descriptors : Hu Moments, Haralick Texture and Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|          image_path|new_label|         descriptors|\n",
      "+--------------------+---------+--------------------+\n",
      "|/Users/mma525/Doc...|        0|[0.015090854, 0.0...|\n",
      "|/Users/mma525/Doc...|        0|[0.12612872, 0.11...|\n",
      "|/Users/mma525/Doc...|        0|[0.09986997, 0.02...|\n",
      "|/Users/mma525/Doc...|        0|[0.3424064, 0.038...|\n",
      "+--------------------+---------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "import mahotas\n",
    "\n",
    "def fetch_descriptor(img):\n",
    "    image = cv2.imread(img)\n",
    "    image = cv2.resize(image, (500, 500))\n",
    "    \n",
    "    im_1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fv_hu_moments = cv2.HuMoments(cv2.moments(im_1)).flatten().tolist()\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    fv_haralick = mahotas.features.haralick(gray).mean(axis=0).flatten().tolist()\n",
    "    \n",
    "    bins =8\n",
    "    # change to HSV \n",
    "    imm = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # find the color histogram\n",
    "    hist  = cv2.calcHist([imm], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    # histogram normalization\n",
    "    cv2.normalize(hist, hist)\n",
    "    \n",
    "    fv_histogram = hist.flatten().tolist()\n",
    "    \n",
    "    # concatenate the 3 feature \n",
    "    final_descriptor = fv_histogram+fv_haralick+fv_hu_moments\n",
    "    \n",
    "    return final_descriptor\n",
    "\n",
    "udf_image = udf(fetch_descriptor, ArrayType(FloatType()))\n",
    "\n",
    "\n",
    "train_descriptor = select_train.withColumn(\"descriptors\", udf_image(\"image_path\"))\n",
    "train_descriptor = train_descriptor.filter(train_descriptor.descriptors. isNotNull())\n",
    "\n",
    "test_descriptor = select_test.withColumn(\"descriptors\", udf_image(\"image_path\"))\n",
    "test_descriptor = test_descriptor.filter(test_descriptor.descriptors. isNotNull())\n",
    "\n",
    "#train_descriptor.show(4)\n",
    "test_descriptor.show(4)\n",
    "#print(train_descriptor.count())\n",
    "print(test_descriptor.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "train_with_vec = train_descriptor.withColumn(\"vec_descriptors\", list_to_vector_udf(\"descriptors\"))\n",
    "test_with_vec = test_descriptor.withColumn(\"vec_descriptors\", list_to_vector_udf(\"descriptors\"))\n",
    "\n",
    "# print(\"Total train examples: \",train_with_vec.count())\n",
    "# print(\"Total test examples: \",test_with_vec.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training into 90/10 into train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+--------------------+\n",
      "|          image_path|new_label|         descriptors|     vec_descriptors|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|/Users/mma525/Doc...|        1|[0.03601592, 0.03...|[0.03601592034101...|\n",
      "|/Users/mma525/Doc...|        1|[0.0, 0.006120887...|[0.0,0.0061208875...|\n",
      "|/Users/mma525/Doc...|        1|[0.4169933, 0.217...|[0.41699329018592...|\n",
      "|/Users/mma525/Doc...|        1|[0.27934158, 0.09...|[0.27934157848358...|\n",
      "|/Users/mma525/Doc...|        1|[0.0023198084, 0....|[0.00231980835087...|\n",
      "|/Users/mma525/Doc...|        1|[0.2190629, 0.195...|[0.21906289458274...|\n",
      "|/Users/mma525/Doc...|        1|[0.15192017, 0.12...|[0.15192016959190...|\n",
      "|/Users/mma525/Doc...|        1|[0.04534819, 0.07...|[0.04534818977117...|\n",
      "|/Users/mma525/Doc...|        1|[0.08312031, 0.08...|[0.08312030881643...|\n",
      "|/Users/mma525/Doc...|        1|[0.068923436, 0.0...|[0.06892343610525...|\n",
      "|/Users/mma525/Doc...|        1|[0.013667441, 0.1...|[0.01366744097322...|\n",
      "|/Users/mma525/Doc...|        1|[0.021968504, 0.1...|[0.02196850441396...|\n",
      "|/Users/mma525/Doc...|        1|[0.11912374, 0.03...|[0.11912374198436...|\n",
      "|/Users/mma525/Doc...|        1|[0.11382823, 0.28...|[0.11382822692394...|\n",
      "|/Users/mma525/Doc...|        1|[0.2696951, 0.059...|[0.26969510316848...|\n",
      "|/Users/mma525/Doc...|        1|[0.26048335, 0.14...|[0.26048335433006...|\n",
      "|/Users/mma525/Doc...|        1|[0.031080853, 0.1...|[0.03108085319399...|\n",
      "|/Users/mma525/Doc...|        1|[0.28926072, 0.32...|[0.28926071524620...|\n",
      "|/Users/mma525/Doc...|        1|[0.09824796, 0.18...|[0.09824796020984...|\n",
      "|/Users/mma525/Doc...|        1|[0.08905092, 0.10...|[0.08905091881752...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|          image_path|new_label|         descriptors|     vec_descriptors|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "|/Users/mma525/Doc...|        1|[0.37825048, 0.18...|[0.37825047969818...|\n",
      "|/Users/mma525/Doc...|        1|[0.4238245, 0.239...|[0.42382448911666...|\n",
      "|/Users/mma525/Doc...|        1|[0.026805004, 0.1...|[0.02680500410497...|\n",
      "|/Users/mma525/Doc...|        1|[0.0, 0.015862841...|[0.0,0.0158628411...|\n",
      "|/Users/mma525/Doc...|        1|[0.08035148, 0.05...|[0.08035147935152...|\n",
      "|/Users/mma525/Doc...|        0|[0.2906193, 0.188...|[0.29061931371688...|\n",
      "|/Users/mma525/Doc...|        0|[0.24935684, 0.15...|[0.24935683608055...|\n",
      "|/Users/mma525/Doc...|        0|[0.18706389, 0.19...|[0.18706388771533...|\n",
      "|/Users/mma525/Doc...|        0|[0.18625242, 0.15...|[0.18625241518020...|\n",
      "|/Users/mma525/Doc...|        0|[0.028265435, 0.0...|[0.02826543524861...|\n",
      "|/Users/mma525/Doc...|        0|[0.26974845, 0.16...|[0.26974844932556...|\n",
      "|/Users/mma525/Doc...|        0|[0.3421624, 0.115...|[0.34216240048408...|\n",
      "|/Users/mma525/Doc...|        0|[0.62175673, 0.34...|[0.62175673246383...|\n",
      "|/Users/mma525/Doc...|        0|[0.4907319, 0.206...|[0.49073189496994...|\n",
      "|/Users/mma525/Doc...|        0|[0.23550889, 0.19...|[0.23550888895988...|\n",
      "|/Users/mma525/Doc...|        0|[0.29853234, 0.15...|[0.29853233695030...|\n",
      "|/Users/mma525/Doc...|        0|[0.2659487, 0.104...|[0.26594871282577...|\n",
      "|/Users/mma525/Doc...|        0|[0.30123687, 0.20...|[0.30123686790466...|\n",
      "|/Users/mma525/Doc...|        0|[0.40403083, 0.18...|[0.40403082966804...|\n",
      "|/Users/mma525/Doc...|        0|[0.41942176, 0.20...|[0.41942176222801...|\n",
      "+--------------------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, val = train_with_vec.randomSplit([0.9, 0.1])\n",
    "train.show()\n",
    "val.show()\n",
    "# print(\"Total train split: \",train.count())\n",
    "# print(\"Total validation split: \",val.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model and train on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logistic_regression = LogisticRegression(featuresCol = 'vec_descriptors', labelCol = 'new_label', maxIter=100)\n",
    "logistic_regression_model = logistic_regression.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        1|[0.24766249816287...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.25253832007836...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.25565537911483...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.24931572951512...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train = logistic_regression_model.transform(train)\n",
    "predictions_train.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Area Under ROC:  0.9219045256220604\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Train Area Under ROC: ', evaluator.evaluate(predictions_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7473772555602182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Train Accuracy: ', evaluator.evaluate(predictions_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        1|[0.24945619709254...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.25469124804894...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.24967060904034...|       1.0|\n",
      "|/Users/mma525/Doc...|        1|[0.25399986404169...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_val = logistic_regression_model.transform(val)\n",
    "predictions_val.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Area Under ROC:  0.9184118673647469\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Val Area Under ROC: ', evaluator.evaluate(predictions_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy:  0.7346153846153847\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Val Accuracy: ', evaluator.evaluate(predictions_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+----------+\n",
      "|          image_path|new_label|         probability|prediction|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "|/Users/mma525/Doc...|        0|[0.25581789941654...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[0.25705819765774...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[0.25725671745614...|       1.0|\n",
      "|/Users/mma525/Doc...|        0|[0.25874611885734...|       1.0|\n",
      "+--------------------+---------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = test_with_vec\n",
    "predictions_test = logistic_regression_model.transform(test)\n",
    "predictions_test.select(\"image_path\",\"new_label\",\"probability\", \"prediction\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.8611439842209088\n"
     ]
    }
   ],
   "source": [
    "# Here we evaluate\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='probability', labelCol='new_label', metricName='areaUnderROC')\n",
    "print('Test Area Under ROC: ', evaluator.evaluate(predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.625\n"
     ]
    }
   ],
   "source": [
    "# multiclassclassification evaluator is used in order to measure accuracy\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='new_label', metricName='accuracy')\n",
    "print('Test Accuracy: ', evaluator.evaluate(predictions_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
